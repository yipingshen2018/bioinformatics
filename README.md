
# ğŸ§¬ Protein Structure Prediction Platform (ColabFold + RunPod)

This platform enables fast and scalable protein 3D structure prediction using [ColabFold](https://github.com/sokrypton/ColabFold) (a wrapper around AlphaFold2) and remote GPU acceleration on [RunPod.io](https://www.runpod.io/). It provides:

- ğŸš€ Remote GPU-based inference
- âš™ï¸ FastAPI backend for upload and management
- ğŸ§µ Celery worker with Redis queue for asynchronous tasks
- ğŸ“ Local storage of uploaded and predicted results

---

## ğŸ“ Project Structure

```
protein-predict-platform/
â”œâ”€â”€ backend/                # FastAPI app (main.py)
â”œâ”€â”€ worker/                 # Celery task handlers (tasks.py)
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ inputs/             # Uploaded FASTA files
â”‚   â””â”€â”€ outputs/            # Downloaded PDB results from RunPod
â”œâ”€â”€ docker-compose.yml      # Service orchestration
â””â”€â”€ README.md               # This documentation
```

## ğŸ§¬ System Architecture

![System Architecture](docs/architecture.png)

---

## ğŸ” Workflow Overview

1. User uploads a `.fasta` file to `/submit` API.
2. Backend stores it under `storage/inputs/`.
3. Celery dispatches a task to the worker.
4. Worker:
   - Connects to RunPod via SSH
   - Uploads the input
   - Runs `colabfold_batch` inside remote GPU environment
   - Downloads prediction results (e.g., `result_model_1.pdb`)
5. Output is saved locally under `storage/outputs/<task_id>`

---

## âš¡ Quickstart

### 1. Start the Platform Locally

```bash
docker-compose up --build
```

- FastAPI available at `http://localhost:8000`
- Celery + Redis initialized automatically

---

### 2. Submit a Prediction

```bash
curl -X POST http://localhost:8000/submit \
  -F "file=@test.fasta"
```

The server will return a success response and begin processing asynchronously.

---

## ğŸ”‘ Remote GPU Access

Prediction runs remotely on a RunPod container over SSH. To configure this:

1. Set your SSH key as an environment variable:

   ```bash
   export SSH_KEY_PATH=~/.ssh/id_ed25519
   ```

2. In `worker/tasks.py`, the key will be used to connect:
   ```python
   ssh.connect("your.runpod.ip", port=PORT, username="root", key_filename=key_path)
   ```

---

## âš ï¸ Prerequisites

| Component       | Requirement                          |
|-----------------|--------------------------------------|
| Python Runtime  | Dockerized (Python 3.10+)            |
| Remote Host     | RunPod container with ColabFold      |
| GPU Environment | CUDA & cuDNN correctly installed     |
| Local Tools     | Docker & Docker Compose              |

---

## ğŸ”§ Tech Stack

| Layer       | Technology        |
|-------------|-------------------|
| API Server  | FastAPI           |
| Task Queue  | Celery + Redis    |
| Inference   | ColabFold + JAX   |
| Deployment  | Docker Compose    |
| Remote Exec | Paramiko + SCP    |

---

## ğŸ“‚ Output Example

Results are downloaded automatically to:

```
storage/outputs/<uuid>/
â”œâ”€â”€ result_model_1.pdb
â”œâ”€â”€ scores.json
â”œâ”€â”€ ranking_debug.json
```

Each prediction result is isolated in its own task-specific directory.

---

## ğŸ“„ License

 Apache 2.0 .

